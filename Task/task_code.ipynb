{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import cvzone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Connected Component "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_connected_components(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    thresh = cv2.threshold(blur, 100, 255, cv2.THRESH_BINARY)[1]\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(thresh, connectivity=4)\n",
    "    return num_labels, labels, stats, centroids,thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The find_connected_components(frame) function finds 4 connected components in the frame given in parameter\n",
    "\n",
    "It performs pre-image processing to the frame converting it to gray scale, applying gaussian blur and then converting the frame to a binary image. The connectedComponentsWithStats() function inputs a binary image and returns (the number of components found, the x,y coordinates and the height and width(location of component)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising The Components On Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box(frame, stats):\n",
    "    for label, stat in stats.items():\n",
    "        x, y, w, h = stat[:4]\n",
    "        cv2.putText(frame,str(label),(x, y-10),cv2.FONT_HERSHEY_SIMPLEX, 0.3, (36,255,12), 1)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The draw_box(frame, stats) function draws a bounding box around the components being tracked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_image(file):\n",
    "    thresholded_image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    alpha_channel = np.ones_like(thresholded_image, dtype=np.uint8) * 255\n",
    "    alpha_channel[thresholded_image == 255] = 0\n",
    "    rgba_image = cv2.merge((thresholded_image, thresholded_image, thresholded_image, alpha_channel))\n",
    "    cv2.imwrite('transparent_image.png', rgba_image)\n",
    "    return rgba_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trans_image(file) makes white parts of a image transparent, which can then be overlayed onto the video "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fft(signal, fs):\n",
    "    n = len(signal)\n",
    "    fft_result = np.fft.fft(signal)\n",
    "    freqs = np.fft.fftfreq(n, 1/fs)\n",
    "    fft_amp = np.abs(fft_result)\n",
    "    return freqs[:n//2], fft_amp[:n//2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compute_fft(signal, fs) function computes the FFT of an input signal and returns the frequency axis and the corresponding amplitude spectrum up to the Nyquist frequency, excluding the mirrored half.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(video):\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    frame_width = int(cap.get(3)) \n",
    "    frame_height = int(cap.get(4)) \n",
    "    size = (frame_width, frame_height) \n",
    "    vidSave = cv2.VideoWriter('Thresh_overlay_frame.mp4',  cv2.VideoWriter_fourcc(*'MPEG'), 8.6, size) \n",
    "    \n",
    "    tracked_components = defaultdict(dict) # saves the stats of the components being tracked \n",
    "    component_intensity = defaultdict(list)# saves the mean intensity of a component at each frame\n",
    "    results = defaultdict(list)\n",
    "    res_final = []#saves the frame number, label and dominant frequency of components that have 0-1 Hz frequency\n",
    "\n",
    "    #loops through all the frames in the video\n",
    "    for frame_index in range(total_frames):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)  \n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        #true when 1 minute has passed it calls the find_connected_components(frame) function and gets the components to be tracked for the next minute \n",
    "        #then the results that were tracked in the previous minute are printed.\n",
    "        if frame_index % int(512) == 0:\n",
    "            #connected compnents recalculated\n",
    "            print(f\"TOTAL NUMBER OF COMPONENTS THAT HAVE BEEN TRACKED {num_labels - 1}:\") if frame_index!=0 else print(\"\")\n",
    "            num_labels, labels, stats, _ ,thresh= find_connected_components(frame)\n",
    "            k=0\n",
    "            #saving the thresholded image to overlay onto the original video to observe the areas of video in focus\n",
    "            cv2.imwrite(f'threshnew.png', thresh)\n",
    "            imgFront=trans_image('threshnew.png')\n",
    "\n",
    "            #printing the mean intensity of each component frame by frame\n",
    "            for label, intensity in results.items():\n",
    "                print(f\"Results for component {label}:\")\n",
    "                for frame_index,l, m_intensity in intensity:\n",
    "                    print(f\"Frame {frame_index}: Intensity of Component {m_intensity}\")\n",
    "            \n",
    "            # printing graph and finding dominant frequncy\n",
    "            for label, intensities in component_intensity.items():\n",
    "                freqs, fft_amp = compute_fft(intensities, fs=fps)\n",
    "                fft_amp[0] = 0; #sets 0 Hz (DC component) to zero\n",
    "                dom_freq = freqs[np.argmax(fft_amp)]#finding the frequency of the element with highest fft_amplitude(dominant frequency)\n",
    "                print(f\"Component {label}: Highest Frequency (Hz): {dom_freq}\")\n",
    "                plt.plot(freqs, fft_amp)\n",
    "                plt.title(f\"FFT of Intensity for Component {label} (frequency domain)\")\n",
    "                plt.xlabel(\"Frequency (Hz)\")\n",
    "                plt.ylabel(\"Amplitude\")\n",
    "                plt.grid(True)\n",
    "                plt.show()\n",
    "                if(dom_freq<=1.0):\n",
    "                    res_final.append([f\"{frame_index - 511} to {frame_index}\",label,dom_freq])\n",
    "            \n",
    "            # resets the lists and dictionaries\n",
    "            tracked_components.clear()\n",
    "            component_intensity.clear()\n",
    "            results.clear()  \n",
    "\n",
    "        imgRes = cvzone.overlayPNG(frame,imgFront,[0,0])\n",
    "        #cv2.imshow(\"new\",imgRes)\n",
    "\n",
    "        #loops through all the components and finds the mean intensity of the component in that frame and append this value to the component_intensity list.\n",
    "        for label in range(1, num_labels):\n",
    "            x, y, w, h, _ = stats[label]  \n",
    "            label_mask = (labels == label).astype(np.uint8) \n",
    "            mean_intensity = cv2.mean(frame, mask=label_mask)[0]\n",
    "            tracked_components[label] = (x, y, w, h)\n",
    "            component_intensity[label].append(mean_intensity)\n",
    "        \n",
    "        #appends all relevant information extracted from that frame to results so that it can be easily printed.\n",
    "        for label, (x, y, w, h) in tracked_components.items():\n",
    "                results[label].append((frame_index,label, component_intensity[label][k]))\n",
    "        k+=1    \n",
    "        \n",
    "        # bounding boxes for components being tracked\n",
    "        for label, (x, y, w, h) in tracked_components.items():\n",
    "            draw_box(frame, {label: (x, y, w, h)})\n",
    "                \n",
    "        # video display\n",
    "        vidSave.write(frame) \n",
    "        cv2.imshow('Frame', frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "             break\n",
    "        \n",
    "    # after video is stoped prints the final list of components\n",
    "    df = pd.DataFrame(res_final, columns =['            Frame    ', 'label', 'frequency'])\n",
    "    print(df)\n",
    "    \n",
    "    cap.release()\n",
    "    vidSave.release() \n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used mean intensity, instead of centroid's intensity:\n",
    "The centroid of the component detected in the first frame, might not have a significant intensity change in the consequent frames. However, the intensity of the areas covered by the rest of the component might change drastically which would not be detected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video = '1705951007967.mp4'  \n",
    "    main(video)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fcbd7240ee8f908d933dc7f71e8c42a1a91163b70ede8dcff5146d4087436c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
